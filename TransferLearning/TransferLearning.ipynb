{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 识别羊驼和熊猫的分类模型\n",
    "### 1. 准备数据集\n",
    "### 200 张羊驼和熊猫 - 训练集\n",
    "### 100 张羊驼和熊猫 - 测试集\n",
    "### 2. 使用 datasets.ImageFolder 对手动整理的数据进行管理和加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms,models\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms.Compose() 函数可以包含多个数据预处理的方法\n",
    "# 1. 训练集图片自适应缩小至最大边长为 230 的大小\n",
    "# 2. 使用居中裁切的方式切割成 224 x 224 的小图\n",
    "# 3. 为了增加训练集的多样性, 进行随机水平翻转\n",
    "# 4. 将图像转化成 Tensor 格式\n",
    "# 5. 进行均值为 0.5, 标准差为 0.5 的归一化\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Scale(230),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置数据集的文件夹路径变量\n",
    "data_directory = 'data' # 与代码文件同目录下的 data 文件夹\n",
    "\n",
    "# datasets.ImageFolder(数据集的文件夹路径, 相应的数据预处理方式)\n",
    "trainset = datasets.ImageFolder(os.path.join(data_directory, 'train'), data_transforms['train'])\n",
    "testset = datasets.ImageFolder(os.path.join(data_directory, 'test'), data_transforms['test'])\n",
    "\n",
    "# DataLoader(数据集, 批处理大小, 遍历不同批次的数据打乱顺序, 使用 4 个子进程来加载数据)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 5, shuffle = True, num_workers = 4)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 5, shuffle = True, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 使用 matplotlib 展示随机加载的训练样本\n",
    "import matplotlib.pyplot as plt\n",
    "def imshow(inputs):\n",
    "    \n",
    "    inputs = inputs / 2 + 0.5\n",
    "    inputs = inputs.numpy().transpose((1, 2, 0))\n",
    "    print(inputs)\n",
    "    plt.imshow(inputs)\n",
    "    plt.show()\n",
    "    \n",
    "inputs,classes = next(iter(trainloader))\n",
    "\n",
    "imshow(torchvision.utils.make_grid(inputs))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision 的 models 包含 AlexNet, VGG, ResNet, SqueezeNet\n",
    "alexnet = models.alexnet(pretrained = True) # 选择预训练好的 AlexNet 模型\n",
    "print(alexnet) # 打印模型结构\n",
    "# features 模块 - 提取特征, 卷积为主\n",
    "# classifier 模块 - 分类, 全连接为主"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造二元分类器 - 重新定义 classifier \n",
    "# 限制参数更新   \n",
    "for param in alexnet.parameters():\n",
    "    param.requires_grad = False \n",
    "    \n",
    "# 重新定义 classifier 模块\n",
    "# 重新定义的 classifier 模块(全连接层)的参数则默认保持 requires_grad = True, 从而可以保证迁移学习的过程中只更新全连接层的参数\n",
    "alexnet.classifier = nn.Sequential(\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(256*6*6, 4096),\n",
    "    nn.ReLU(inplace = True),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(4096, 4096),\n",
    "    nn.ReLU(inplace = True),\n",
    "    nn.Linear(4096, 2),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "if CUDA:\n",
    "    alexnet = alexnet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(alexnet.classifier.parameters(), lr = 0.001, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,criterion, optimizer, epochs = 1):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs,labels = data\n",
    "            if CUDA:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            running_loss += loss.item()\n",
    "            if i % 10 == 9:\n",
    "                print('[Epoch: %d, Batch: %5d] Loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    " \n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(testloader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        if CUDA:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1) \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "    print('Accuracy on the test set: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_param(model, path):\n",
    "    if os.path.exists(path):\n",
    "        model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_param(model, path):\n",
    "    torch.save(model.state_dict(),path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_param(alexnet, 'tl_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(alexnet, criterion, optimizer, epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_param(alexnet, 'tl_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(testloader, alexnet) # 经历 2 轮的遍历训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
